{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e333ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6137720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # stopwords (most common words that don't mean much)\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "\n",
    "# Initialize spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# load the dataframe from an excel file. For now keep an unedited copy and one to manipulate\n",
    "og_df = pd.read_csv(\"/Users/GlassShark1/Python/Refusals Data/All Refusals 2019-2022 w devtypes.csv\")\n",
    "df = og_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df33c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_display_max(max_rows):\n",
    "    # set display so you can see all columns, all rows and all cell contents (up to 1k characters)\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.set_option('display.max_rows', max_rows)\n",
    "    pd.options.display.max_colwidth = 1000\n",
    "    \n",
    "# set JN to display full extent of data\n",
    "jupyter_display_max(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281b6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    \n",
    "    # replaces instances of more than 1 space with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # strips any unwanted whitespace from either end\n",
    "    text = text.rstrip().lstrip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7417f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saints_rule(text):\n",
    "    # removes full stop in St. before extracting parish names so it is not read as a full stop\n",
    "    if 'St. ' in text:\n",
    "        text.replace('St. ', 'St ')\n",
    "    #specific case where the word 'form' skews results, but we don't want to lose 'information'\n",
    "    if ' form' in text:\n",
    "        text.replace( ' form', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f088c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple func to return length. Used to apply to a list of values\n",
    "def leng_func(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7df0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a set of values to be replaced with a single value\n",
    "def replace_text(text, string_set, returnstr):\n",
    "    for string in string_set:\n",
    "        text = text.replace(string, returnstr)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbcfdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col_by_labels(df,column_names):\n",
    "    for col in column_names:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25127763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perm_regex(text):\n",
    "    \n",
    "    # Identify permission references\n",
    "    matchtype = r'(?i)(?:PA)?\\d{2}[/|_]\\d{5}' # e.g. PA12/12345\n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "    \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d258b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLP_regex(text):\n",
    "    matchtype = r'(Cornwall Local Plan Strategic Policies|Cornwall Local Plan|CLP) (?:\\d{4}\\s*-\\s*\\d{4}|\\d{4}?)?'\n",
    "    #matchtype = r'(Cornwall Local Plan Strategic Policies|Cornwall Local Plan|CLP)\\s*((\\(\\d{4}(?:\\s*-\\s*\\d{4})?\\))|\\d{4}\\s*-\\s*\\d{4}|\\d{4})?'\n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "        \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1fa69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AONB_regex(text):\n",
    "    matchtype = r'(?i)\\barea\\s*of\\s*outstanding\\s*natural\\s*beauty\\b|\\bAONB\\b|\\(AONB\\)'\n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "        \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e787129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPD_regex(text):\n",
    "    matchtype = r'\\b(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\s+(?:N(?:eighbourhood)?\\s*(?:D(?:evelopment)?\\s*)?P(?:lan)?|NDP)\\b(?:\\s+\\([^\\)]+\\))?(?:\\s+\\d{4}(?:\\s*(?:to|-)\\s*\\d{4})?)?'    \n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "        \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02a56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to match categories in the text and create category columns\n",
    "def match_categories(text):\n",
    "    \n",
    "    # initializes a PhraseMatcher object named matcher using the vocabulary of the nlp model\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    # empty dictionary to store the matched category sentences\n",
    "    category_sentences = {}\n",
    "\n",
    "    # for each category and it's examples - this bit is about getting the matcher to understand your patterns\n",
    "    # and store them efficiently. It is an instance of the PhraseMatcher class\n",
    "    for category, examples in example_snippets.items():\n",
    "        # converts into spaCy Doc objects\n",
    "        category_patterns = [nlp(example) for example in examples]\n",
    "        # adds them to the matcher object\n",
    "        matcher.add(category, None, *category_patterns)\n",
    "        # initializes empty list for each category in the category_sentences dictionary\n",
    "        category_sentences[category] = []\n",
    "\n",
    "    # processes the input text using the nlp model, creating a Doc object named doc\n",
    "    doc = nlp(text)\n",
    "    # matches the patterns in the matcher object against the doc, obtains matches in the matches variable\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # iterates over each match and retrieves the matched category and sentence\n",
    "    for match_id, start, end in matches:\n",
    "        matched_category = matcher.vocab.strings[match_id]\n",
    "        matched_sentence = doc[start:end].text\n",
    "        #  appends matched sentence to the corresponding category in the category_sentences dictionary\n",
    "        category_sentences[matched_category].append(matched_sentence)\n",
    "    \n",
    "    return category_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aa870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b636edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces (spell check TBD)\n",
    "df['RefusalReasons'] = df['RefusalReasons'].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "210a1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidying up refusalreasons text and extracting key info in columns\n",
    "\n",
    "\n",
    "# get rid of confusing 'St.' strings\n",
    "df[\"RefusalReasons\"] = df[\"RefusalReasons\"].apply(saints_rule)\n",
    "# create a column containing a string of references to NPDs\n",
    "df['NDPs Referenced'] = df[\"RefusalReasons\"].apply(NPD_regex)\n",
    "# create a column containing a string of references to CLP\n",
    "df['CLPs Referenced'] = df[\"RefusalReasons\"].apply(CLP_regex)\n",
    "# create a column containing a string of permission references\n",
    "df['Perms Referenced'] = df[\"RefusalReasons\"].apply(Perm_regex)\n",
    "# create a column containing a string of AONB references\n",
    "df['AONB Referenced'] = df[\"RefusalReasons\"].apply(AONB_regex)\n",
    "# Tidy the various AONB references to return only 'AONB'\n",
    "# replace null values with empty string\n",
    "df['AONB Referenced'].fillna('', inplace=True)\n",
    "# update non-null values with 'AONB'\n",
    "df.loc[df['AONB Referenced'] != '', 'AONB Referenced'] = 'AONB'\n",
    "# replace all iterations of AONB with 'AONB' in the main data\n",
    "#df['RefusalReasons'] = df['RefusalReasons'].apply(replace_text, args=(all_AONB_list, 'AONB'))\n",
    "# drop unused columns\n",
    "df = drop_col_by_labels(df,['Unnamed: 0','Missing Dev_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''First cut the source data down by exluding categories that don't share common refusal reasons - e.g.\n",
    "very specific types of development\n",
    "\n",
    "# maybe exclude:\n",
    "# CLUED - Certificate of Lawful Development - these generally refer to whether the use of something\n",
    "# is lawful or not, so typically refusal reasons differ here\n",
    "# TPO/TPA - Tree Protection  - generally refusals are for public amenity reasons\n",
    "#'Listed Building Consent (alter/extend)' - borderline one because it's to do with alterations/extensions\n",
    "\n",
    "exclude_cats = ['CLEUD/CLOPED','TPO applications','Not Required - Hedgerow Removal','TCA applications']\n",
    "# Prior Approval - AF2 type == agricultural stuff?\n",
    "borderline_cats = ['Listed Building Consent (alter/extend)','Prior Approval - AF2 type','Notification - Rail type']\n",
    "\n",
    "# filter categories to exclude from the df. '~' negates/gives you the opposite of something\n",
    "df = df[~df['Dev_Type'].isin(exclude_cats)]\n",
    "\n",
    "# as you've removed entries from the index, they will be out of order, reset to fix\n",
    "# also required when applying boolean masks later, or when merging on results by index later\n",
    "df = df.reset_index()\n",
    "\n",
    "# intital text stripping, including phrases as opposed words and common sentences\n",
    "# plus stripping of perm references etc, plus stripping of lemmatized versions of text_to_remove\n",
    "df['cleaned'] = df['RefusalReasons'].apply(strip_specific_text)\n",
    "\n",
    "df['cleaned'] = df['cleaned'].apply(strip_numbers)\n",
    "\n",
    "df['cleaned'] = df['cleaned'].apply(stopwords_and_preprocess)\n",
    "\n",
    "# 'cleaned' is an object datatype, cast as str to allow you to search for substrings for refinement\n",
    "df['checking col'] = df['cleaned'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c87d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary, each category is the key, each key has a list of snippets\n",
    "example_snippets = {\n",
    "    'Flooding and Drainage': [\n",
    "        'flood risk',\n",
    "        'flood zones',\n",
    "        'flood risk assessment',\n",
    "        'not been demonstrated that the site is safe from flooding',\n",
    "        'policy 26',\n",
    "        'other available sites at a lower risk of flooding',\n",
    "        'significant risk of flooding',\n",
    "        'not acceptable in terms of the risk of flooding',\n",
    "        'critical drainage area.',\n",
    "        'functional floodplain',\n",
    "        'would not be appropriately flood resilient',\n",
    "        'would not be safe access or egress in a 1 in 100-year flood event',\n",
    "        'drainage strategy',\n",
    "        'surface water drainage disposal',\n",
    "        'surface water disposal'\n",
    "    ],\n",
    "    'Neighbours and amenities': [\n",
    "        'overlooking',\n",
    "        'overbearing',\n",
    "        'intrusive',\n",
    "        'elevated postion',\n",
    "        'impact upon occupiers neighbouring',\n",
    "        'losses of privacy',\n",
    "        'privacy loss',\n",
    "        'scale, form, massing and proximity to the neighbouring',\n",
    "        'loss of light',\n",
    "        'neighbouring residents',\n",
    "        'amenity enjoyed',\n",
    "        'paragraphs 127 and 130 of the national planning policy framework',\n",
    "        'noise disturbance',\n",
    "        'public amenity',\n",
    "        'loss of an area of public open space',\n",
    "        'loss of amenity',\n",
    "        'noise and disturbance',\n",
    "        'residential amenity',\n",
    "        'neighbouring dwellings',\n",
    "        'no arboricultural evidence',\n",
    "        'amenity value'\n",
    "        \n",
    "    ],\n",
    "    'Access, Road Safety': [\n",
    "        'vehicular traffic',\n",
    "        'lack of accessibility to services',\n",
    "        'limited visibility',\n",
    "        'increased risk of collision',\n",
    "        'highway safety',\n",
    "        'safe and suitable access',\n",
    "        'vehicle and pedestrian conflict',\n",
    "        'poor visibility',\n",
    "        'accessing and egressing',\n",
    "        'safe or suitable passing',\n",
    "        'manoeuvring space',\n",
    "        'passing space',\n",
    "        'policy 27',\n",
    "        'congestion',\n",
    "        'safe and suitable access to the site for all users',\n",
    "        'impact on the local road network',\n",
    "        'no appropriate access',\n",
    "        'reliant on private motor vehicles'\n",
    "    ],\n",
    "    'History and Heritage': [\n",
    "        'historic mining',\n",
    "        'eroding its historic character',\n",
    "        'whs',\n",
    "        'world heritage site',\n",
    "        'historic functional relationship',\n",
    "        'heritage asset',\n",
    "        'area of great landscape value',\n",
    "        'historic settlement',\n",
    "        'record of the morphology',\n",
    "        'historic impact assessment',\n",
    "        'authenticity and integrity',\n",
    "        'designated  assets',\n",
    "        'listed building',\n",
    "        'historic interest'\n",
    "    ],\n",
    "    'Open Countryside': [\n",
    "        'open countryside',\n",
    "        'open-countryside',\n",
    "        'countryside location',\n",
    "        'in the countryside',\n",
    "        'isolated rural dwelling',\n",
    "        'increase the urban built form',\n",
    "        'divorced from any settlement',\n",
    "        'introduction of built form',\n",
    "        'outside of the defined settlement boundaries',\n",
    "        'sporadic',\n",
    "        'unmistakably rural',\n",
    "        'unsustainable form of development',\n",
    "        'intrinsic character',\n",
    "        'unsustainable and undesirable',\n",
    "        'reliance on private vehicle',\n",
    "        'not sustainable development',\n",
    "        'unsustainable traffic movements'\n",
    "    ],\n",
    "    'AH': [\n",
    "        'affordable housing need',\n",
    "        'need for affordable housing ',\n",
    "        'not affordable housing led',\n",
    "        'no affordable housing provision'\n",
    "    ],\n",
    "    'Conservation and Biodiversity': [\n",
    "        'biodiversty',\n",
    "        'bio-diversity',\n",
    "        'environmental harm',\n",
    "        'special area of conservation ',\n",
    "        ' sac ',\n",
    "        'bats',\n",
    "        'reptiles',\n",
    "        'birds',\n",
    "        'insects',\n",
    "        'habitat',\n",
    "        'species',\n",
    "        'site of special scientific interest',\n",
    "        'sssi',\n",
    "        'protect the natural environment',\n",
    "        'foraging',\n",
    "        'wildlife',\n",
    "        'derogation',\n",
    "        'ecological'\n",
    "        'woodland',\n",
    "        'marsh'\n",
    "    ],\n",
    "    'Design': [\n",
    "        'fail to respect its form',\n",
    "        'by virtue of its design',\n",
    "        'traditional pattern of development',\n",
    "        'by reason of its form',\n",
    "        'established pattern',\n",
    "        'existing built form',\n",
    "        'incongruous',\n",
    "        'discordant',\n",
    "        'uncharacteristic',\n",
    "        'scale and massing',\n",
    "        'disproportionate',\n",
    "        'detrimental to the street scene',\n",
    "        'design guide',\n",
    "        'poor design',\n",
    "        'fail to reflect local distinctiveness',\n",
    "        'fail to integrate',\n",
    "        'unsympathetic material',\n",
    "        'cramped',\n",
    "        'contrived',\n",
    "        'established character of the area',\n",
    "        'local character',\n",
    "        'functional appearance',\n",
    "        'bulk',\n",
    "        'character of the building',\n",
    "        'dominate the street scene'\n",
    "        \n",
    "    ],\n",
    "    'Landscape, Appearance, Character': [\n",
    "        'area of outstanding natural beauty',\n",
    "        'heritage coast',\n",
    "        'scenic',\n",
    "        'beauty',\n",
    "        'harm the rural characteristics',\n",
    "        'visable from the public',\n",
    "        'landscape character',\n",
    "        'character and appearance',\n",
    "        'widely visable',\n",
    "        'area of great landscape value',\n",
    "        'aglv',\n",
    "        'dominant feature',\n",
    "        'landscape harm',\n",
    "        'harmful to the character',\n",
    "        'harmful visual impact',\n",
    "        'appearance and character',\n",
    "        'character of the area'\n",
    "        \n",
    "    ],\n",
    "    'Occupancy evidence': [\n",
    "        'not been used an independant residential',\n",
    "        'demonstrating independent occupation',\n",
    "        'not been used for residential purposes',\n",
    "        'in excess of 10 years',\n",
    "        'in excess of ten years',\n",
    "        'in excess of 10yrs',\n",
    "        'breach of the occupancy condition',\n",
    "        'been used for domestic purposes' \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b4a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple list of all the categories above for headers and to create dfs later\n",
    "all_cats_list = []\n",
    "for k,v in example_snippets.items():\n",
    "    all_cats_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5044a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooding and Drainage\n",
      "['flood risk', 'flood zones', 'flood risk assessment', 'not been demonstrated that the site is safe from flooding', 'policy 26', 'other available sites at a lower risk of flooding', 'significant risk of flooding', 'not acceptable in terms of the risk of flooding', 'critical drainage area.', 'functional floodplain', 'would not be appropriately flood resilient', 'would not be safe access or egress in a 1 in 100-year flood event', 'drainage strategy', 'surface water drainage disposal', 'surface water disposal']\n",
      "\n",
      "\n",
      "Neighbours and amenities\n",
      "['overlooking', 'overbearing', 'intrusive', 'elevated postion', 'impact upon occupiers neighbouring', 'losses of privacy', 'privacy loss', 'scale, form, massing and proximity to the neighbouring', 'loss of light', 'neighbouring residents', 'amenity enjoyed', 'paragraphs 127 and 130 of the national planning policy framework', 'noise disturbance', 'public amenity', 'loss of an area of public open space', 'loss of amenity', 'noise and disturbance', 'residential amenity', 'neighbouring dwellings', 'no arboricultural evidence', 'amenity value']\n",
      "\n",
      "\n",
      "Access, Road Safety\n",
      "['vehicular traffic', 'lack of accessibility to services', 'limited visibility', 'increased risk of collision', 'highway safety', 'safe and suitable access', 'vehicle and pedestrian conflict', 'poor visibility', 'accessing and egressing', 'safe or suitable passing', 'manoeuvring space', 'passing space', 'policy 27', 'congestion', 'safe and suitable access to the site for all users', 'impact on the local road network', 'no appropriate access', 'reliant on private motor vehicles']\n",
      "\n",
      "\n",
      "History and Heritage\n",
      "['historic mining', 'eroding its historic character', 'whs', 'world heritage site', 'historic functional relationship', 'heritage asset', 'area of great landscape value', 'historic settlement', 'record of the morphology', 'historic impact assessment', 'authenticity and integrity', 'designated  assets', 'listed building', 'historic interest']\n",
      "\n",
      "\n",
      "Open Countryside\n",
      "['open countryside', 'open-countryside', 'countryside location', 'in the countryside', 'isolated rural dwelling', 'increase the urban built form', 'divorced from any settlement', 'introduction of built form', 'outside of the defined settlement boundaries', 'sporadic', 'unmistakably rural', 'unsustainable form of development', 'intrinsic character', 'unsustainable and undesirable', 'reliance on private vehicle', 'not sustainable development', 'unsustainable traffic movements']\n",
      "\n",
      "\n",
      "AH\n",
      "['affordable housing need', 'need for affordable housing ', 'not affordable housing led', 'no affordable housing provision']\n",
      "\n",
      "\n",
      "Conservation and Biodiversity\n",
      "['biodiversty', 'bio-diversity', 'environmental harm', 'special area of conservation ', ' sac ', 'bats', 'reptiles', 'birds', 'insects', 'habitat', 'species', 'site of special scientific interest', 'sssi', 'protect the natural environment', 'foraging', 'wildlife', 'derogation', 'ecologicalwoodland', 'marsh']\n",
      "\n",
      "\n",
      "Design\n",
      "['fail to respect its form', 'by virtue of its design', 'traditional pattern of development', 'by reason of its form', 'established pattern', 'existing built form', 'incongruous', 'discordant', 'uncharacteristic', 'scale and massing', 'disproportionate', 'detrimental to the street scene', 'design guide', 'poor design', 'fail to reflect local distinctiveness', 'fail to integrate', 'unsympathetic material', 'cramped', 'contrived', 'established character of the area', 'local character', 'functional appearance', 'bulk', 'character of the building', 'dominate the street scene']\n",
      "\n",
      "\n",
      "Landscape, Appearance, Character\n",
      "['area of outstanding natural beauty', 'heritage coast', 'scenic', 'beauty', 'harm the rural characteristics', 'visable from the public', 'landscape character', 'character and appearance', 'widely visable', 'area of great landscape value', 'aglv', 'dominant feature', 'landscape harm', 'harmful to the character', 'harmful visual impact', 'appearance and character', 'character of the area']\n",
      "\n",
      "\n",
      "Occupancy evidence\n",
      "['not been used an independant residential', 'demonstrating independent occupation', 'not been used for residential purposes', 'in excess of 10 years', 'in excess of ten years', 'in ecesss of 10yrs', 'breach of the occupancy condition', 'been used for domestic purposes']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in example_snippets.items():\n",
    "    print(k),\n",
    "    print(v)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "418eb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RefusalReasons'] = df['RefusalReasons'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28757ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'RefusalReasons' column\n",
    "category_sentences = df['RefusalReasons'].apply(match_categories).tolist()\n",
    "\n",
    "# create a df from the dictionary category_sentences, that has columns for each cat and rows for each record\n",
    "category_df = pd.DataFrame(category_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "684303f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the category columns with the original DataFrame\n",
    "df = pd.concat([df, category_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44d84975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each category, make the column values string (not object) and remove empty lists\n",
    "for col in all_cats_list:\n",
    "    df[col] = df[col].astype(str)\n",
    "df = df.replace('[]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76ef9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of empty strings in each row within the specified columns. strip in case there is whitespace\n",
    "df['blank_count'] = df[all_cats_list].apply(lambda row: row.str.strip().eq('').sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd794263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooding and Drainage\n",
      "Neighbours and amenities\n",
      "Access, Road Safety\n",
      "History and Heritage\n",
      "Open Countryside\n",
      "AH\n",
      "Conservation and Biodiversity\n",
      "Design\n",
      "Landscape, Appearance, Character\n",
      "Occupancy evidence\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary to hold a df per category, filtering out any with no matches for that category\n",
    "cat_dict = {}\n",
    "for col in all_cats_list:\n",
    "    cat_dict[col] = df.copy()\n",
    "    cat_dict[col] = cat_dict[col][cat_dict[col][col] != \"\"]\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35d9f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_specific_text(text):\n",
    "    \n",
    "    text_to_remove = [\n",
    "        \"Cornwall Local Plan Strategic Policies 2010 - 2030\",\n",
    "        \"Cornwall Local Plan Strategic Policies 2010-2030\",\n",
    "        \"Cornwall Local Plan Strategic Policies\",\n",
    "        \"CLP\",\n",
    "        \"Cornwall Local Plan\",\n",
    "        \"policies\",\n",
    "        \"National Planning Policy Framework\",\n",
    "        \"NPPF\",\n",
    "        \"paragraph\",\n",
    "        \"paragraphs\"\n",
    "    ]\n",
    "    \n",
    "    # for each thing you want to remove from the text\n",
    "    for phrase in text_to_remove:\n",
    "        # if the lower case version is in the lower case version of the text, replace it with nothing (delete)\n",
    "        if phrase.lower() in text.lower():\n",
    "            #print(phrase, \" in text\")\n",
    "            text = text.replace(phrase.lower(), \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0474e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_category_values(df):\n",
    "    \n",
    "    # simplify the data, showing only 1/0 output if a record is tagged with a category\n",
    "    # create these as new columns with suffix '_ML'\n",
    "    for category in all_cats_list:\n",
    "        #replace any nulls with zero\n",
    "        df[category +'_ML'] = df[category].fillna(0)\n",
    "        df[category +'_ML'] = df[category +'_ML'].replace('',0)\n",
    "        df[category +'_ML'] = df[category +'_ML'].apply(lambda x: 1 if x != 0 else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1943100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Lemmatize each token and join them back into a string\n",
    "    text = ' '.join([token.lemma_ for token in doc])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9fee071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "\n",
    "    # first make message lower case to make other operations simpler\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove unwanted/not useful text/phrases from the string\n",
    "    text = strip_specific_text(text)\n",
    "    \n",
    "    # remove any number references\n",
    "    # create a list of characters if the character is a letter or a space\n",
    "    text = [char for char in text if char.isalpha() or char == \" \"]\n",
    "    # join the characters again with 'nothing' - as spaces are included above\n",
    "    text = \"\".join(text)\n",
    "    \n",
    "    # Check characters to see if they are in punctuation\n",
    "    text = [char for char in text if char not in string.punctuation]\n",
    "    # Join the characters again to form the string without punctuation\n",
    "    text = ''.join(text)\n",
    "    \n",
    "    # convert the msg without punctuation to a string of lemmas\n",
    "    text = lemma(text)\n",
    "    \n",
    "    # Now just remove any stopwords, return as a list to be vectorized\n",
    "    return [word for word in text.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43c49fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binary_category_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53fceb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b1d5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flooding and Drainage_ML', 'Neighbours and amenities_ML', 'Access, Road Safety_ML', 'History and Heritage_ML', 'Open Countryside_ML', 'AH_ML', 'Conservation and Biodiversity_ML', 'Design_ML', 'Landscape, Appearance, Character_ML', 'Occupancy evidence_ML']\n"
     ]
    }
   ],
   "source": [
    "allcatslist = []\n",
    "for col in df.columns:\n",
    "    if col[-2:] == 'ML':\n",
    "        allcatslist.append(col)\n",
    "    \n",
    "print(allcatslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ae7f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GlassShark1/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/GlassShark1/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "\n",
    "classification_dict = {}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(df['RefusalReasons'], df[allcatslist], test_size=0.2)\n",
    "\n",
    "# Pipeline takes a list of tuples (name of the step, what it's doing)\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('clf', ClassifierChain(SVC(probability=True))),  # Apply Binary Relevance with SVM classifier\n",
    "])\n",
    "\n",
    "# Fit the data to the model\n",
    "pipeline.fit(msg_train, label_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "probs = pipeline.predict_proba(msg_test)\n",
    "\n",
    "# Adjust the threshold to control classification outcome\n",
    "threshold = 0.5  # Adjust the threshold as desired\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "# Compute precision, recall, and other metrics\n",
    "report = classification_report(label_test, preds, target_names=allcatslist, output_dict=True)\n",
    "\n",
    "# Make a dataframe from the dictionary\n",
    "df_report = pd.DataFrame(report)\n",
    "\n",
    "# Add the report into a dictionary of reports\n",
    "#classification_dict[category] = df_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "150eb6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flooding and Drainage_ML</th>\n",
       "      <th>Neighbours and amenities_ML</th>\n",
       "      <th>Access, Road Safety_ML</th>\n",
       "      <th>History and Heritage_ML</th>\n",
       "      <th>Open Countryside_ML</th>\n",
       "      <th>AH_ML</th>\n",
       "      <th>Conservation and Biodiversity_ML</th>\n",
       "      <th>Design_ML</th>\n",
       "      <th>Landscape, Appearance, Character_ML</th>\n",
       "      <th>Occupancy evidence_ML</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>samples avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.874126</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.878307</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.862016</td>\n",
       "      <td>0.847493</td>\n",
       "      <td>0.860865</td>\n",
       "      <td>0.738956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818851</td>\n",
       "      <td>0.791403</td>\n",
       "      <td>0.818851</td>\n",
       "      <td>0.713494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.729282</td>\n",
       "      <td>0.836272</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.839879</td>\n",
       "      <td>0.815856</td>\n",
       "      <td>0.837241</td>\n",
       "      <td>0.708558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>679.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Flooding and Drainage_ML  Neighbours and amenities_ML  \\\n",
       "precision                  1.000000                     0.840000   \n",
       "recall                     0.937500                     0.724138   \n",
       "f1-score                   0.967742                     0.777778   \n",
       "support                   16.000000                    58.000000   \n",
       "\n",
       "           Access, Road Safety_ML  History and Heritage_ML  \\\n",
       "precision                0.950000                 0.814286   \n",
       "recall                   0.974359                 0.890625   \n",
       "f1-score                 0.962025                 0.850746   \n",
       "support                 39.000000                64.000000   \n",
       "\n",
       "           Open Countryside_ML     AH_ML  Conservation and Biodiversity_ML  \\\n",
       "precision             0.874126  0.666667                          0.836735   \n",
       "recall                0.925926  0.500000                          0.836735   \n",
       "f1-score              0.899281  0.571429                          0.836735   \n",
       "support             135.000000  4.000000                         49.000000   \n",
       "\n",
       "            Design_ML  Landscape, Appearance, Character_ML  \\\n",
       "precision    0.814815                             0.878307   \n",
       "recall       0.660000                             0.798077   \n",
       "f1-score     0.729282                             0.836272   \n",
       "support    100.000000                           208.000000   \n",
       "\n",
       "           Occupancy evidence_ML   micro avg   macro avg  weighted avg  \\\n",
       "precision               0.800000    0.862016    0.847493      0.860865   \n",
       "recall                  0.666667    0.818851    0.791403      0.818851   \n",
       "f1-score                0.727273    0.839879    0.815856      0.837241   \n",
       "support                 6.000000  679.000000  679.000000    679.000000   \n",
       "\n",
       "           samples avg  \n",
       "precision     0.738956  \n",
       "recall        0.713494  \n",
       "f1-score      0.708558  \n",
       "support     679.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41327626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "precision == abilty to detect true positives (ratio of true postives to true postitives + false positives)\n",
    "recall == also ability to detect true positives, but is ratio of true positives to true positives + false positives)\n",
    "F1 Score: Harmonic mean of precision and recall. 1 == best possible score\n",
    "support == number of instances of the category found in the test dataset, according to the model alone.\n",
    "support does not have anything to do with the original labels.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c190234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_excel(df, filename, sheet_name=None):\n",
    "\n",
    "    from pathlib import Path\n",
    "    path = \"/Users/GlassShark1/Python/Refusals Data/\"\n",
    "    filepath = Path(path + filename + \".xlsx\")\n",
    "    print(filepath)\n",
    "\n",
    "    if sheet_name is None:\n",
    "        df.to_excel(filepath, index=False)\n",
    "    else:\n",
    "        df.to_excel(filepath, index=False, sheet_name=sheet_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "249d3d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/GlassShark1/Python/Refusals Data/Verbatim_Ref_Reasons_280523.xlsx\n",
      "/Users/GlassShark1/Python/Refusals Data/VRR_class_rpt_280523.xlsx\n"
     ]
    }
   ],
   "source": [
    "export_excel(df, \"Verbatim_Ref_Reasons_280523\", sheet_name=\"Data\")\n",
    "export_excel(df_report,\"VRR_class_rpt_280523\", sheet_name=\"class_rpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90306fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0058a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "LEMMA VERSION STARTS HERE\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Initialize spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load the dataframe from an Excel file. For now, keep an unedited copy and one to manipulate\n",
    "og_df = pd.read_csv(\"/Users/GlassShark1/Python/Refusals Data/All Refusals 2019-2022 w devtypes.csv\")\n",
    "df = og_df.copy()\n",
    "\n",
    "example_snippets = {\n",
    "    'Flooding and Drainage': [\n",
    "        [{'LOWER': 'flood', 'LEMMA': 'flood'}, {'IS_ALPHA': True, 'OP': '*'}, {'LOWER': 'risk', 'LEMMA': 'risk'}],\n",
    "        [{'LOWER': 'flood', 'LEMMA': 'flood'}, {'LOWER': 'zone', 'LEMMA': 'zone'}],\n",
    "        [{'LOWER': 'demonstrate', 'LEMMA': 'demonstrate'}, {'LOWER': 'safe', 'LEMMA': 'safe'}, {'LOWER': 'flood', 'LEMMA': 'flood'}],\n",
    "        [{'LOWER': 'policy', 'LEMMA': 'policy'}, {'LOWER': '26'}],\n",
    "        [{'LOWER': 'available', 'LEMMA': 'available'}, {'LOWER': 'site', 'LEMMA': 'site'}, {'LOWER': 'low', 'LEMMA': 'low'}, {'LOWER': 'risk', 'LEMMA': 'risk'}, {'LOWER': 'flood', 'LEMMA': 'flood'}],\n",
    "        [{'LOWER': 'significant', 'LEMMA': 'significant'}, {'LOWER': 'risk', 'LEMMA': 'risk'}, {'LOWER': 'flood', 'LEMMA': 'flood'}],\n",
    "        [{'LOWER': 'not'}, {'LOWER': 'acceptable', 'LEMMA': 'acceptable'}, {'LOWER': 'term', 'LEMMA': 'term'}, {'LOWER': 'risk', 'LEMMA': 'risk'}, {'LOWER': 'flood', 'LEMMA': 'flood'}],\n",
    "        [{'LOWER': 'critical', 'LEMMA': 'critical'}, {'LOWER': 'drainage', 'LEMMA': 'drainage'}, {'LOWER': 'area', 'LEMMA': 'area'}],\n",
    "        [{'LOWER': 'functional', 'LEMMA': 'functional'}, {'LOWER': 'floodplain', 'LEMMA': 'floodplain'}],\n",
    "        [{'LOWER': 'would'}, {'LOWER': 'not'}, {'LOWER': 'appropriately', 'LEMMA': 'appropriately'}, {'LOWER': 'flood', 'LEMMA': 'flood'}, {'LOWER': 'resilient', 'LEMMA': 'resilient'}],\n",
    "        [{'LOWER': 'would'}, {'LOWER': 'not'}, {'LOWER': 'safe', 'LEMMA': 'safe'}, {'LOWER': 'access', 'LEMMA': 'access'}, {'LOWER': 'egress', 'LEMMA': 'egress'}, {'LOWER': '1'}, {'LOWER': '100'}, {'LOWER': 'year'}, {'LOWER': 'flood', 'LEMMA': 'flood'}, {'LOWER': 'event', 'LEMMA': 'event'}],\n",
    "        [{'LOWER': 'drainage', 'LEMMA': 'drainage'}, {'LOWER': 'strategy', 'LEMMA': 'strategy'}],\n",
    "        [{'LOWER': 'surface', 'LEMMA': 'surface'}, {'LOWER': 'water', 'LEMMA': 'water'}, {'LOWER': 'drainage', 'LEMMA': 'drainage'}, {'LOWER': 'disposal', 'LEMMA': 'disposal'}],\n",
    "        [{'LOWER': 'surface', 'LEMMA': 'surface'}, {'LOWER': 'water', 'LEMMA': 'water'}, {'LOWER': 'disposal', 'LEMMA': 'disposal'}]\n",
    "    ],\n",
    "    'Neighbours and amenities': [\n",
    "        [{'LOWER': 'overlooking', 'LEMMA': 'overlook'}],\n",
    "        [{'LOWER': 'overbearing', 'LEMMA': 'overbear'}],\n",
    "        [{'LOWER': 'intrusive', 'LEMMA': 'intrusive'}],\n",
    "        [{'LOWER': 'elevated', 'LEMMA': 'elevate'}, {'LOWER': 'position', 'LEMMA': 'position'}],\n",
    "        [{'LOWER': 'impact', 'LEMMA': 'impact'}, {'LOWER': 'occupier', 'LEMMA': 'occupier'}, {'LOWER': 'neighbouring', 'LEMMA': 'neighbour'}],\n",
    "        [{'LOWER': 'loss', 'LEMMA': 'loss'}, {'LOWER': 'privacy', 'LEMMA': 'privacy'}],\n",
    "        [{'LOWER': 'privacy', 'LEMMA': 'privacy'}, {'LOWER': 'loss', 'LEMMA': 'loss'}],\n",
    "        [{'LOWER': 'scale', 'LEMMA': 'scale'}, {'LOWER': 'form', 'LEMMA': 'form'}, {'LOWER': 'massing', 'LEMMA': 'mass'}, {'LOWER': 'proximity', 'LEMMA': 'proximity'}, {'LOWER': 'neighbouring', 'LEMMA': 'neighbour'}],\n",
    "        [{'LOWER': 'loss', 'LEMMA': 'loss'}, {'LOWER': 'light', 'LEMMA': 'light'}],\n",
    "        [{'LOWER': 'neighbouring', 'LEMMA': 'neighbour'}, {'LOWER': 'resident', 'LEMMA': 'resident'}],\n",
    "        [{'LOWER': 'amenity', 'LEMMA': 'amenity'}, {'LOWER': 'enjoy', 'LEMMA': 'enjoy'}],\n",
    "        [{'LOWER': 'paragraph', 'LEMMA': 'paragraph'}, {'LOWER': '127'}, {'LOWER': '130'}, {'LOWER': 'national', 'LEMMA': 'national'}, {'LOWER': 'planning', 'LEMMA': 'plan'}, {'LOWER': 'policy', 'LEMMA': 'policy'}, {'LOWER': 'framework', 'LEMMA': 'framework'}],\n",
    "        [{'LOWER': 'noise', 'LEMMA': 'noise'}, {'LOWER': 'disturbance', 'LEMMA': 'disturbance'}]\n",
    "    ],\n",
    "    'No appropriate access': [\n",
    "        [{'LOWER': 'vehicular', 'LEMMA': 'vehicular'}, {'LOWER': 'traffic', 'LEMMA': 'traffic'}],\n",
    "        [{'LOWER': 'accessibility', 'LEMMA': 'accessibility'}, {'LOWER': 'service', 'LEMMA': 'service'}],\n",
    "        [{'LOWER': 'limited', 'LEMMA': 'limited'}, {'LOWER': 'visibility', 'LEMMA': 'visibility'}],\n",
    "        [{'LOWER': 'increased', 'LEMMA': 'increase'}, {'LOWER': 'risk', 'LEMMA': 'risk'}, {'LOWER': 'collision', 'LEMMA': 'collision'}],\n",
    "        [{'LOWER': 'highway', 'LEMMA': 'highway'}, {'LOWER': 'safety', 'LEMMA': 'safety'}],\n",
    "        [{'LOWER': 'safe', 'LEMMA': 'safe'}, {'LOWER': 'suitable', 'LEMMA': 'suitable'}, {'LOWER': 'access', 'LEMMA': 'access'}],\n",
    "        [{'LOWER': 'vehicle', 'LEMMA': 'vehicle'}, {'LOWER': 'pedestrian', 'LEMMA': 'pedestrian'}, {'LOWER': 'conflict', 'LEMMA': 'conflict'}],\n",
    "        [{'LOWER': 'poor', 'LEMMA': 'poor'}, {'LOWER': 'visibility', 'LEMMA': 'visibility'}],\n",
    "        [{'LOWER': 'accessing', 'LEMMA': 'access'}, {'LOWER': 'egressing', 'LEMMA': 'egress'}],\n",
    "        [{'LOWER': 'safe', 'LEMMA': 'safe'}, {'LOWER': 'suitable', 'LEMMA': 'suitable'}, {'LOWER': 'pass', 'LEMMA': 'pass'}],\n",
    "        [{'LOWER': 'manoeuvring', 'LEMMA': 'manoeuvre'}, {'LOWER': 'space', 'LEMMA': 'space'}],\n",
    "        [{'LOWER': 'passing', 'LEMMA': 'pass'}, {'LOWER': 'space', 'LEMMA': 'space'}],\n",
    "        [{'LOWER': 'policy', 'LEMMA': 'policy'}, {'LOWER': '27'}],\n",
    "        [{'LOWER': 'congestion', 'LEMMA': 'congestion'}],\n",
    "        [{'LOWER': 'safe', 'LEMMA': 'safe'}, {'LOWER': 'suitable', 'LEMMA': 'suitable'}, {'LOWER': 'access', 'LEMMA': 'access'}, {'LOWER': 'site', 'LEMMA': 'site'}, {'LOWER': 'user', 'LEMMA': 'user'}],\n",
    "        [{'LOWER': 'impact', 'LEMMA': 'impact'}, {'LOWER': 'local', 'LEMMA': 'local'}, {'LOWER': 'road', 'LEMMA': 'road'}, {'LOWER': 'network', 'LEMMA': 'network'}]\n",
    "    ],\n",
    "    'History and Heritage': [\n",
    "        [{'LOWER': 'historic', 'LEMMA': 'historic'}, {'LOWER': 'mining', 'LEMMA': 'mining'}],\n",
    "        [{'LOWER': 'erode', 'LEMMA': 'erode'}, {'LOWER': 'historic', 'LEMMA': 'historic'}, {'LOWER': 'character', 'LEMMA': 'character'}],\n",
    "        [{'LOWER': 'WHS', 'LEMMA': 'WHS'}, {'LOWER': 'world', 'LEMMA': 'world'}, {'LOWER': 'heritage', 'LEMMA': 'heritage'}, {'LOWER': 'site', 'LEMMA': 'site'}],\n",
    "        [{'LOWER': 'historic', 'LEMMA': 'historic'}, {'LOWER': 'functional', 'LEMMA': 'functional'}, {'LOWER': 'relationship', 'LEMMA': 'relationship'}],\n",
    "        [{'LOWER': 'heritage', 'LEMMA': 'heritage'}, {'LOWER': 'asset', 'LEMMA': 'asset'}],\n",
    "        [{'LOWER': 'area', 'LEMMA': 'area'}, {'LOWER': 'great', 'LEMMA': 'great'}, {'LOWER': 'landscape', 'LEMMA': 'landscape'}, {'LOWER': 'value', 'LEMMA': 'value'}],\n",
    "        [{'LOWER': 'historic', 'LEMMA': 'historic'}, {'LOWER': 'settlement', 'LEMMA': 'settlement'}],\n",
    "        [{'LOWER': 'record', 'LEMMA': 'record'}, {'LOWER': 'morphology', 'LEMMA': 'morphology'}],\n",
    "        [{'LOWER': 'historic', 'LEMMA': 'historic'}, {'LOWER': 'impact', 'LEMMA': 'impact'}, {'LOWER': 'assessment', 'LEMMA': 'assessment'}],\n",
    "        [{'LOWER': 'authenticity', 'LEMMA': 'authenticity'}, {'LOWER': 'integrity', 'LEMMA': 'integrity'}],\n",
    "        [{'LOWER': 'designate', 'LEMMA': 'designate'}, {'LOWER': 'asset', 'LEMMA': 'asset'}],\n",
    "        [{'LOWER': 'list', 'LEMMA': 'list'}, {'LOWER': 'building', 'LEMMA': 'building'}]\n",
    "    ],\n",
    "    'Open Countryside': [\n",
    "        [{'LOWER': 'open', 'LEMMA': 'open'}, {'LOWER': 'countryside', 'LEMMA': 'countryside'}],\n",
    "        [{'LOWER': 'increase', 'LEMMA': 'increase'}, {'LOWER': 'encroachment', 'LEMMA': 'encroachment'}],\n",
    "        [{'LOWER': 'scenic', 'LEMMA': 'scenic'}, {'LOWER': 'beauty', 'LEMMA': 'beauty'}, {'LOWER': 'area', 'LEMMA': 'area'}],\n",
    "        [{'LOWER': 'green', 'LEMMA': 'green'}, {'LOWER': 'wedge', 'LEMMA': 'wedge'}],\n",
    "        [{'LOWER': 'open', 'LEMMA': 'open'}, {'LOWER': 'area', 'LEMMA': 'area'}, {'LOWER': 'restrain', 'LEMMA': 'restrain'}],\n",
    "        [{'LOWER': 'natural', 'LEMMA': 'natural'}, {'LOWER': 'landscape', 'LEMMA': 'landscape'}, {'LOWER': 'feature', 'LEMMA': 'feature'}],\n",
    "        [{'LOWER': 'visual', 'LEMMA': 'visual'}, {'LOWER': 'amenity', 'LEMMA': 'amenity'}],\n",
    "        [{'LOWER': 'promote', 'LEMMA': 'promote'}, {'LOWER': 'recreation', 'LEMMA': 'recreation'}, {'LOWER': 'amenity', 'LEMMA': 'amenity'}],\n",
    "        [{'LOWER': 'open', 'LEMMA': 'open'}, {'LOWER': 'space', 'LEMMA': 'space'}],\n",
    "        [{'LOWER': 'policy', 'LEMMA': 'policy'}, {'LOWER': '35'}],\n",
    "        [{'LOWER': 'valued', 'LEMMA': 'value'}, {'LOWER': 'landscape', 'LEMMA': 'landscape'}, {'LOWER': 'feature', 'LEMMA': 'feature'}],\n",
    "        [{'LOWER': 'impact', 'LEMMA': 'impact'}, {'LOWER': 'character', 'LEMMA': 'character'}, {'LOWER': 'area', 'LEMMA': 'area'}]\n",
    "    ],\n",
    "        'AH': [\n",
    "        [{'LOWER': 'affordable', 'LEMMA': 'affordable'}, {'LOWER': 'housing', 'LEMMA': 'housing'}, {'LOWER': 'need', 'LEMMA': 'need'}],\n",
    "        [{'LOWER': 'need', 'LEMMA': 'need'}, {'LOWER': 'for', 'LEMMA': 'for'}, {'LOWER': 'affordable', 'LEMMA': 'affordable'}, {'LOWER': 'housing', 'LEMMA': 'housing'}],\n",
    "        [{'LOWER': 'no', 'LEMMA': 'no'}, {'LOWER': 'affordable', 'LEMMA': 'affordable'}, {'LOWER': 'housing', 'LEMMA': 'housing'}, {'LOWER': 'provision', 'LEMMA': 'provision'}],\n",
    "        [{'LOWER': 'not', 'LEMMA': 'not'}, {'LOWER': 'affordable', 'LEMMA': 'affordable'}, {'LOWER': 'housing', 'LEMMA': 'housing'}, {'LOWER': 'led', 'LEMMA': 'led'}]\n",
    "    ],\n",
    "    'Conservation and Biodiversity': [\n",
    "        [{'LOWER': 'biodiversty', 'LEMMA': 'biodiversity'}],\n",
    "        [{'LOWER': 'special', 'LEMMA': 'special'}, {'LOWER': 'area', 'LEMMA': 'area'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'conservation', 'LEMMA': 'conservation'}],\n",
    "        [{'LOWER': 'SAC', 'LEMMA': 'SAC'}, {'LOWER': 'site', 'LEMMA': 'site'}],\n",
    "        [{'LOWER': 'bat', 'LEMMA': 'bat'}, {'LOWER': 'species', 'LEMMA': 'species'}],\n",
    "        [{'LOWER': 'reptile', 'LEMMA': 'reptile'}, {'LOWER': 'species', 'LEMMA': 'species'}],\n",
    "        [{'LOWER': 'bird', 'LEMMA': 'bird'}, {'LOWER': 'species', 'LEMMA': 'species'}],\n",
    "        [{'LOWER': 'insect', 'LEMMA': 'insect'}, {'LOWER': 'species', 'LEMMA': 'species'}],\n",
    "        [{'LOWER': 'habitat', 'LEMMA': 'habitat'}],\n",
    "        [{'LOWER': 'species', 'LEMMA': 'species'}],\n",
    "        [{'LOWER': 'site', 'LEMMA': 'site'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'special', 'LEMMA': 'special'}, {'LOWER': 'scientific', 'LEMMA': 'scientific'}, {'LOWER': 'interest', 'LEMMA': 'interest'}],\n",
    "        [{'LOWER': 'SSSI', 'LEMMA': 'SSSI'}, {'LOWER': 'site', 'LEMMA': 'site'}],\n",
    "        [{'LOWER': 'protect', 'LEMMA': 'protect'}, {'LOWER': 'the', 'LEMMA': 'the'}, {'LOWER': 'natural', 'LEMMA': 'natural'}, {'LOWER': 'environment', 'LEMMA': 'environment'}],\n",
    "        [{'LOWER': 'ecological', 'LEMMA': 'ecological'}, {'LOWER': 'woodland', 'LEMMA': 'woodland'}],\n",
    "        [{'LOWER': 'foraging', 'LEMMA': 'foraging'}],\n",
    "        [{'LOWER': 'marsh', 'LEMMA': 'marsh'}],\n",
    "        [{'LOWER': 'wildlife', 'LEMMA': 'wildlife'}],\n",
    "        [{'LOWER': 'derogation', 'LEMMA': 'derogation'}]\n",
    "    ],\n",
    "    'Design': [\n",
    "        [{'LOWER': 'fail', 'LEMMA': 'fail'}, {'LOWER': 'to', 'LEMMA': 'to'}, {'LOWER': 'respect', 'LEMMA': 'respect'}, {'LOWER': 'its', 'LEMMA': 'its'}, {'LOWER': 'form', 'LEMMA': 'form'}],\n",
    "        [{'LOWER': 'traditional', 'LEMMA': 'traditional'}, {'LOWER': 'pattern', 'LEMMA': 'pattern'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'development', 'LEMMA': 'development'}],\n",
    "        [{'LOWER': 'by', 'LEMMA': 'by'}, {'LOWER': 'reason', 'LEMMA': 'reason'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'its', 'LEMMA': 'its'}, {'LOWER': 'form', 'LEMMA': 'form'}],\n",
    "        [{'LOWER': 'established', 'LEMMA': 'established'}, {'LOWER': 'pattern', 'LEMMA': 'pattern'}],\n",
    "        [{'LOWER': 'existing', 'LEMMA': 'existing'}, {'LOWER': 'built', 'LEMMA': 'built'}, {'LOWER': 'form', 'LEMMA': 'form'}],\n",
    "        [{'LOWER': 'incongruous', 'LEMMA': 'incongruous'}],\n",
    "        [{'LOWER': 'discordant', 'LEMMA': 'discordant'}],\n",
    "        [{'LOWER': 'uncharacteristic', 'LEMMA': 'uncharacteristic'}],\n",
    "        [{'LOWER': 'scale', 'LEMMA': 'scale'}, {'LOWER': 'and', 'LEMMA': 'and'}, {'LOWER': 'massing', 'LEMMA': 'massing'}],\n",
    "        [{'LOWER': 'disproportionate', 'LEMMA': 'disproportionate'}],\n",
    "        [{'LOWER': 'detrimental', 'LEMMA': 'detrimental'}, {'LOWER': 'to', 'LEMMA': 'to'}, {'LOWER': 'the', 'LEMMA': 'the'}, {'LOWER': 'street', 'LEMMA': 'street'}, {'LOWER': 'scene', 'LEMMA': 'scene'}],\n",
    "        [{'LOWER': 'design', 'LEMMA': 'design'}, {'LOWER': 'guide', 'LEMMA': 'guide'}],\n",
    "        [{'LOWER': 'poor', 'LEMMA': 'poor'}, {'LOWER': 'design', 'LEMMA': 'design'}],\n",
    "        [{'LOWER': 'fail', 'LEMMA': 'fail'}, {'LOWER': 'to', 'LEMMA': 'to'}, {'LOWER': 'reflect', 'LEMMA': 'reflect'}, {'LOWER': 'local', 'LEMMA': 'local'}, {'LOWER': 'distinctiveness', 'LEMMA': 'distinctiveness'}],\n",
    "        [{'LOWER': 'fail', 'LEMMA': 'fail'}, {'LOWER': 'to', 'LEMMA': 'to'}, {'LOWER': 'integrate', 'LEMMA': 'integrate'}],\n",
    "        [{'LOWER': 'cramped', 'LEMMA': 'cramped'}],\n",
    "        [{'LOWER': 'contrived', 'LEMMA': 'contrived'}],\n",
    "        [{'LOWER': 'established', 'LEMMA': 'established'}, {'LOWER': 'character', 'LEMMA': 'character'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'the', 'LEMMA': 'the'}, {'LOWER': 'area', 'LEMMA': 'area'}],\n",
    "        [{'LOWER': 'local', 'LEMMA': 'local'}, {'LOWER': 'character', 'LEMMA': 'character'}],\n",
    "        [{'LOWER': 'unsympathetic', 'LEMMA': 'unsympathetic'},{'LOWER': 'material', 'LEMMA': 'material'}],\n",
    "        [{'LOWER': 'functional', 'LEMMA': 'functional'}, {'LOWER': 'appearance', 'LEMMA': 'appearance'}],\n",
    "        [{'LOWER': 'bulk', 'LEMMA': 'bulk'}]\n",
    "    ],\n",
    "    'Landscape and Appearance': [\n",
    "        [{'LOWER': 'area', 'LEMMA': 'area'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'outstanding', 'LEMMA': 'outstanding'}, {'LOWER': 'natural', 'LEMMA': 'natural'}, {'LOWER': 'beauty', 'LEMMA': 'beauty'}],\n",
    "        [{'LOWER': 'heritage', 'LEMMA': 'heritage'}, {'LOWER': 'coast', 'LEMMA': 'coast'}],\n",
    "        [{'LOWER': 'scenic', 'LEMMA': 'scenic'}],\n",
    "        [{'LOWER': 'beauty', 'LEMMA': 'beauty'}],\n",
    "        [{'LOWER': 'harm', 'LEMMA': 'harm'}, {'LOWER': 'the', 'LEMMA': 'the'}, {'LOWER': 'rural', 'LEMMA': 'rural'}, {'LOWER': 'characteristics', 'LEMMA': 'characteristic'}],\n",
    "        [{'LOWER': 'visable', 'LEMMA': 'visible'}, {'LOWER': 'from', 'LEMMA': 'from'}, {'LOWER': 'the', 'LEMMA': 'the'}, {'LOWER': 'public', 'LEMMA': 'public'}],\n",
    "        [{'LOWER': 'landscape', 'LEMMA': 'landscape'}, {'LOWER': 'character', 'LEMMA': 'character'}],\n",
    "        [{'LOWER': 'character', 'LEMMA': 'character'}, {'LOWER': 'and', 'LEMMA': 'and'}, {'LOWER': 'appearance', 'LEMMA': 'appearance'}],\n",
    "        [{'LOWER': 'widely', 'LEMMA': 'widely'}, {'LOWER': 'visible', 'LEMMA': 'visible'}],\n",
    "        [{'LOWER': 'area', 'LEMMA': 'area'}, {'LOWER': 'of', 'LEMMA': 'of'}, {'LOWER': 'great', 'LEMMA': 'great'}, {'LOWER': 'landscape', 'LEMMA': 'landscape'}, {'LOWER': 'value', 'LEMMA': 'value'}],\n",
    "        [{'LOWER': 'AGLV', 'LEMMA': 'AGLV'}]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a simple list of all the categories above for headers and to create dfs later\n",
    "all_cats_list = list(example_snippets.keys())\n",
    "\n",
    "# Define a function to match categories in the text and create category columns\n",
    "def match_categories(text):\n",
    "    # Initializes a PhraseMatcher object named matcher using the vocabulary of the nlp model\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    # Empty dictionary to store the matched category sentences\n",
    "    category_sentences = {}\n",
    "\n",
    "    # Iterate over each category and its examples\n",
    "    for category, examples in example_snippets.items():\n",
    "        # Convert examples into spaCy patterns\n",
    "        category_patterns = [nlp.tokenizer(' '.join([t.get('LOWER', '') for t in example])) for example in examples]\n",
    "\n",
    "        # Add the patterns to the matcher object\n",
    "        matcher.add(category, None, *category_patterns)\n",
    "        # Initialize an empty list for each category in the category_sentences dictionary\n",
    "        category_sentences[category] = []\n",
    "\n",
    "    # Process the input text using the nlp model, creating a Doc object named doc\n",
    "    doc = nlp(text)\n",
    "    # Match the patterns in the matcher object against the doc, obtain matches in the matches variable\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Iterate over each match and retrieve the matched category and sentence\n",
    "    for match_id, start, end in matches:\n",
    "        matched_category = matcher.vocab.strings[match_id]\n",
    "        matched_sentence = doc[start:end].text\n",
    "        # Append the matched sentence to the corresponding category in the category_sentences dictionary\n",
    "        category_sentences[matched_category].append(matched_sentence)\n",
    "\n",
    "    return category_sentences\n",
    "\n",
    "# Apply the function to the 'RefusalReasons' column\n",
    "category_sentences = df['RefusalReasons'].apply(match_categories).tolist()\n",
    "\n",
    "category_df = pd.DataFrame(category_sentences)\n",
    "\n",
    "# Merge the category columns with the original DataFrame\n",
    "df = pd.concat([df, category_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a95d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, examples in example_snippets.items():\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for col in all_cats_list:\n",
    "    df[col] = df[col].astype(str)\n",
    "df = df.replace('[]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_cats_list:\n",
    "    cat_dict[col] = df.copy()\n",
    "    cat_dict[col] = cat_dict[col][cat_dict[col][col] != \"\"]\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adda5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reason in cat_dict['Flooding and Drainage']['Flooding and Drainage']:\n",
    "    print(cat_dict['Flooding and Drainage']['RefusalReasons'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89600d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_dict['Flooding and Drainage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb779a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict['Flooding and Drainage']['RefusalReasons'][1019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8048437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
