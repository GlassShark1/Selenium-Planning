{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743d9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a list of specific words/phrases you want to remove so as to focus on topic modelling\n",
    "# convert Area of Outstanding Natural Beauty to AONB, similar for others\n",
    "\n",
    "text_to_remove = [\n",
    "        \"National Planning Policy Framework\",\n",
    "        \"demonstrate\",\n",
    "        \"section\",\n",
    "        \"work\",\n",
    "        \"intentions\",\n",
    "        \"november\",\n",
    "        \"adopted\",\n",
    "        \"adoption\",\n",
    "        \"represent\",\n",
    "        \"representing\",\n",
    "        \"settlement\",\n",
    "        \"NPPF\",\n",
    "        \"Planning\",\n",
    "        \"Cornwall\",\n",
    "        \"local\",\n",
    "        \"Plan\",\n",
    "        \"Development\",\n",
    "        \"policies\",\n",
    "        \"contrary\",\n",
    "        \"development\",\n",
    "        \"Proposal\",\n",
    "        \"Application\",\n",
    "        \"Policy\",\n",
    "        \"Policies\",\n",
    "        \"paragraph\",\n",
    "        \"paragraphs\",\n",
    "        \"permitted\",\n",
    "        \"development\",\n",
    "        \"area\",\n",
    "        \"dwelling\",\n",
    "        \"proposed\",\n",
    "        \"national\",\n",
    "        \"site\",\n",
    "        \"house\",\n",
    "        \"special\",\n",
    "        \"justify\",\n",
    "        \"town\",\n",
    "        \"constitute\",\n",
    "        \"sited\",\n",
    "        \"siting\",\n",
    "        \"site\",\n",
    "        \"guidance\",\n",
    "        \"benefit\",\n",
    "        \"justification\",\n",
    "        \"point\",\n",
    "        \"raise\",\n",
    "        \"factor\",\n",
    "        \"balance\",\n",
    "        \"house\",\n",
    "        \"identify\",\n",
    "        \"fall\",\n",
    "        \"land \",\n",
    "        \"provide\",\n",
    "        \"circumstances\",\n",
    "        \"considerable\"\n",
    "        # land, fall, house, identify\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cacd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(0) Load df, trim columns. Remove unwanted record categories (trees, lawfulness etc)\\n(1) Extract useful data like NPD references and permissions references and add as columns\\n(1) Preprocess text (remove particular words, remove stopwords, lemmatize)\\n(2) Create dictionary with an int ID for each remaining word\\n(3) Filter the dictionary down if desired, removing very rare or very common words\\n(4) Create BOW for each doc - a list of tuples for each record:\\n    [[(int ref from the dictionary, word frequency)],[(int ref from the dictionary, word frequency)]]\\n(5) Train the lda model, providing the dictionary, no of topics, no of passes etc.\\n(6) Adjust preprocessing steps or variables in (5) to tweak topic model output to meaningful topics\\n(7) Topic model returns a list of topics, with each topic containing tuples of the word id and the probabilities\\nthat the word will feature in a text of that topic\\n(8) Create a topic probabilities dataframe, with each topic in columns and values containing probabilities\\nHOW DOES THIS GET TO A SINGLE PROBABILITY PER RECORD, RATHER THAN PROBABILITIES BY WORD???\\n(9) Add the topic probabilites to original dataframe\\n\\n\\nTO DO:\\n\\n10) Add further columns turning probabilities into boolean values at a given cut off point\\n11) Add logging feature to track outputs with given variables to improve tweaking performance\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "(0) Load df, trim columns. Remove unwanted record categories (trees, lawfulness etc)\n",
    "(1) Extract useful data like NPD references and permissions references and add as columns\n",
    "(1) Preprocess text (remove particular words, remove stopwords, lemmatize)\n",
    "(2) Create dictionary with an int ID for each remaining word\n",
    "(3) Filter the dictionary down if desired, removing very rare or very common words\n",
    "(4) Create BOW for each doc - a list of tuples for each record:\n",
    "    [[(int ref from the dictionary, word frequency)],[(int ref from the dictionary, word frequency)]]\n",
    "(5) Train the lda model, providing the dictionary, no of topics, no of passes etc.\n",
    "(6) Adjust preprocessing steps or variables in (5) to tweak topic model output to meaningful topics\n",
    "(7) Topic model returns a list of topics, with each topic containing tuples of the word id and the probabilities\n",
    "that the word will feature in a text of that topic\n",
    "(8) Create a topic probabilities dataframe, with each topic in columns and values containing probabilities\n",
    "HOW DOES THIS GET TO A SINGLE PROBABILITY PER RECORD, RATHER THAN PROBABILITIES BY WORD???\n",
    "(9) Add the topic probabilites to original dataframe\n",
    "\n",
    "\n",
    "TO DO:\n",
    "\n",
    "10) Add further columns turning probabilities into boolean values at a given cut off point\n",
    "11) Add logging feature to track outputs with given variables to improve tweaking performance\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b22a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69421e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet') # might not be needed once run once\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162d1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from an excel file. For now keep an unedited copy and one to manipulate\n",
    "og_df = pd.read_csv(\"/Users/GlassShark1/Python/Refusals Data/All Refusals 2019-2022 w devtypes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71685bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = og_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cf3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_display_max(max_rows):\n",
    "    # set display so you can see all columns, all rows and all cell contents (up to 1k characters)\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.set_option('display.max_rows', max_rows)\n",
    "    pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74c6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col_by_labels(df,column_names):\n",
    "    for col in column_names:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daaaa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_df_down(df):\n",
    "    \n",
    "    #Define attribute columns with data on the permission itself\n",
    "    info_cols = ['Unnamed: 0', 'Address', 'docfragment', 'file_ext', 'filename', 'Decision', 'Link','FromSearch', 'ToSearch', 'AppTypeFrag']\n",
    "    \n",
    "    # Define columns to keep for the NLP work\n",
    "    keep_cols = ['Ref', 'Description', 'Dev_Type','DecDate', 'RefusalReasons']\n",
    "    \n",
    "    # find any other columns not in the above categories to remove - these will be those already manually categorised\n",
    "    x_train_cols = [col for col in df.columns if col not in info_cols and col not in keep_cols]\n",
    "    \n",
    "    # for unsupervised model, remove unneeded cols + manually categorised data\n",
    "    remove_cols = info_cols + x_train_cols\n",
    "    \n",
    "    # remove unwanted columns\n",
    "    df = drop_col_by_labels(df,remove_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52fdd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_numbers(text):\n",
    "    \n",
    "    # create a list of characters if the character is a letter or a space\n",
    "    strip_numbers = [char for char in text if char.isalpha() or char == \" \"]\n",
    "    \n",
    "    # join the characters again with 'nothing' - as spaces are included above\n",
    "    strip_numbers = \"\".join(strip_numbers)\n",
    "    \n",
    "    # return the string\n",
    "    return strip_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b317c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_specific_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    # removes common/unwanted/not valuable text and phrases from string\n",
    "    \n",
    "    # for each thing you want to remove from the text\n",
    "    for phrase in master_list:\n",
    "        # if the lower case version is in the lower case version of the text, replace it with nothing (delete)\n",
    "        if phrase.lower() in text.lower():\n",
    "            #print(phrase, \" in text\")\n",
    "            text = text.replace(phrase.lower(), \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a54aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple func to return length. Used to apply to a list of values\n",
    "def leng_func(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4a1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perm_regex(text):\n",
    "    \n",
    "    # Identify permission references\n",
    "    matchtype = r'(?i)(?:PA)?\\d{2}[/|_]\\d{5}' # e.g. PA12/12345\n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "    \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23da78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLP_regex(text):\n",
    "    matchtype = r'(Cornwall Local Plan Strategic Policies|Cornwall Local Plan|CLP) (?:\\d{4}\\s*-\\s*\\d{4}|\\d{4}?)?'\n",
    "    #matchtype = r'(Cornwall Local Plan Strategic Policies|Cornwall Local Plan|CLP)\\s*((\\(\\d{4}(?:\\s*-\\s*\\d{4})?\\))|\\d{4}\\s*-\\s*\\d{4}|\\d{4})?'\n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "        \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ab20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPD_regex(text):\n",
    "    matchtype = r'\\b(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\s+(?:N(?:eighbourhood)?\\s*(?:D(?:evelopment)?\\s*)?P(?:lan)?|NDP)\\b(?:\\s+\\([^\\)]+\\))?(?:\\s+\\d{4}(?:\\s*(?:to|-)\\s*\\d{4})?)?'    \n",
    "    matches = re.findall(matchtype, text)\n",
    "    \n",
    "    # sort the list by highest number of characters first. This means CLPSP will be replaced before CLP, \n",
    "    # so you aren't left with instances of SP on their own\n",
    "    matches.sort(reverse = True,key=leng_func)\n",
    "    \n",
    "    # Don't return anything if it's an empty list / no matches\n",
    "    if matches ==[]:\n",
    "        matches = \"\"\n",
    "        \n",
    "    # remove dups by set and turn into a single comma seperated string\n",
    "    matches = set(matches)\n",
    "    matches = \",\".join(matches)\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b824c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saints_rule(text):\n",
    "    # removes full stop in St. before extracting parish names so it is not read as a full stop\n",
    "    if 'St. ' in text:\n",
    "        text.replace('St. ', 'St ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b87e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d5db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d4d096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_and_preprocess(text):\n",
    "    # creates a list of all words passed in if they are not stopwords or v.sml and returns lemmatized version\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            # specifiy preprocessing steps here - stemming / lemmatization, both\n",
    "            # result.append(lemmatize_stemming(token))\n",
    "            # result.append(stemming(token))\n",
    "            result.append(lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c072a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_values_in_col(col):\n",
    "    # return a set of all the different values (all values represented only once)\n",
    "    all_list = set(df[col].tolist())\n",
    "    # turn the set into a list\n",
    "    all_list = [item for item in all_list]\n",
    "    \n",
    "    # from the list that can contain sublists, flatten into single list\n",
    "    new_list = []\n",
    "    for item in all_list:\n",
    "        if item == '':\n",
    "            continue\n",
    "        sublist = item.split(',')\n",
    "        for item in sublist:\n",
    "            new_list.append(item)\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa7d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set JN to display full extent of data\n",
    "jupyter_display_max(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24a7998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chop the df down to only the bits you will use\n",
    "df = cut_df_down(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65bae7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of confusing 'St.' strings\n",
    "df[\"RefusalReasons\"] = df[\"RefusalReasons\"].apply(saints_rule)\n",
    "# create a column containing a string of references to NPDs\n",
    "df['NDPs Referenced'] = df[\"RefusalReasons\"].apply(NPD_regex)\n",
    "# create a column containing a string of references to CLP\n",
    "df['CLPs Referenced'] = df[\"RefusalReasons\"].apply(CLP_regex)\n",
    "# create a column containing a string of permission references\n",
    "df['Perms Referenced'] = df[\"RefusalReasons\"].apply(Perm_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be8ecc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from an initial list which could contain lists itself, return a single list containing\n",
    "# all values in the column, cast to a set to remove duplicates\n",
    "all_types_list = set(list_all_values_in_col('Dev_Type'))\n",
    "all_perms_list = set(list_all_values_in_col('Perms Referenced'))\n",
    "all_NPs_list = set(list_all_values_in_col('NDPs Referenced'))\n",
    "all_CLPs_list = set(list_all_values_in_col('CLPs Referenced'))\n",
    "\n",
    "# create a list of all these sets\n",
    "master_list = [all_perms_list, all_NPs_list, all_CLPs_list]\n",
    "# for each of the lists of sets, add all the values together, then convert back to a list for sorting\n",
    "master_list = list(set().union(*master_list))\n",
    "# add the extracted phrases to remove to the more generic phrases you have manually added on exploration\n",
    "master_list = text_to_remove + master_list\n",
    "# sort the values by largest number of characters first (so .replace will be greedy)\n",
    "master_list.sort(reverse = True, key=leng_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4472ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dev_Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minor - Dwelling</th>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Dwelling</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Householder</th>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>Householder</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All other minor developments</th>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>All other minor developments</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLEUD/CLOPED</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>CLEUD/CLOPED</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changes of Use</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>Changes of Use</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPO applications</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>TPO applications</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smallscale Major Dwellings</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>Smallscale Major Dwellings</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Dwelling - PIP apps only</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Dwelling - PIP apps only</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Listed Building Consent (alter/extend)</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>Listed Building Consent (alter/extend)</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All other small scale major developments</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>All other small scale major developments</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not required - S106/S52</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Not required - S106/S52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Advertisements</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Advertisements</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Gypsy and Traveller Sites</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Gypsy and Traveller Sites</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All other largescale major developments</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>All other largescale major developments</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Retail distribution/servicing</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Retail distribution/servicing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Required - Hedgerow Removal</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Required - Hedgerow Removal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification - TEL type</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Notification - TEL type</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior Approval - AF2 type</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Prior Approval - AF2 type</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification - AF types - Bldgs/tracks</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Notification - AF types - Bldgs/tracks</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Largescale Major Dwellings</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Largescale Major Dwellings</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Largescale Major Retail Distri/Servicing</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Largescale Major Retail Distri/Servicing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not required - General</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Not required - General</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smallscale Major Retail Distri/Servicing</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Smallscale Major Retail Distri/Servicing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCA applications</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TCA applications</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Offices/R&amp;D/Light Industry</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Offices/R&amp;D/Light Industry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Largescale Major Hvy Ind/Storage/Whouse</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Largescale Major Hvy Ind/Storage/Whouse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification - Rail type</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Notification - Rail type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exception Notice Not Reqd (was 5day not)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Exception Notice Not Reqd (was 5day not)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor - dwelling</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>minor - dwelling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count unique  \\\n",
       "Dev_Type                                                \n",
       "Minor - Dwelling                          1048      1   \n",
       "Householder                                257      1   \n",
       "All other minor developments               154      1   \n",
       "CLEUD/CLOPED                               144      1   \n",
       "Changes of Use                             103      1   \n",
       "TPO applications                            78      1   \n",
       "Smallscale Major Dwellings                  66      1   \n",
       "Minor - Dwelling - PIP apps only            64      1   \n",
       "Listed Building Consent (alter/extend)      48      1   \n",
       "All other small scale major developments    21      1   \n",
       "Not required - S106/S52                     20      1   \n",
       "Advertisements                              11      1   \n",
       "Minor - Gypsy and Traveller Sites            9      1   \n",
       "All other largescale major developments      8      1   \n",
       "Minor - Retail distribution/servicing        5      1   \n",
       "Not Required - Hedgerow Removal              5      1   \n",
       "Notification - TEL type                      5      1   \n",
       "Prior Approval - AF2 type                    5      1   \n",
       "Notification - AF types - Bldgs/tracks       4      1   \n",
       "Largescale Major Dwellings                   4      1   \n",
       "Largescale Major Retail Distri/Servicing     2      1   \n",
       "Not required - General                       2      1   \n",
       "Smallscale Major Retail Distri/Servicing     2      1   \n",
       "TCA applications                             2      1   \n",
       "Minor - Offices/R&D/Light Industry           1      1   \n",
       "Largescale Major Hvy Ind/Storage/Whouse      1      1   \n",
       "Notification - Rail type                     1      1   \n",
       "Exception Notice Not Reqd (was 5day not)     1      1   \n",
       "minor - dwelling                             1      1   \n",
       "\n",
       "                                                                               top  \\\n",
       "Dev_Type                                                                             \n",
       "Minor - Dwelling                                                  Minor - Dwelling   \n",
       "Householder                                                            Householder   \n",
       "All other minor developments                          All other minor developments   \n",
       "CLEUD/CLOPED                                                          CLEUD/CLOPED   \n",
       "Changes of Use                                                      Changes of Use   \n",
       "TPO applications                                                  TPO applications   \n",
       "Smallscale Major Dwellings                              Smallscale Major Dwellings   \n",
       "Minor - Dwelling - PIP apps only                  Minor - Dwelling - PIP apps only   \n",
       "Listed Building Consent (alter/extend)      Listed Building Consent (alter/extend)   \n",
       "All other small scale major developments  All other small scale major developments   \n",
       "Not required - S106/S52                                    Not required - S106/S52   \n",
       "Advertisements                                                      Advertisements   \n",
       "Minor - Gypsy and Traveller Sites                Minor - Gypsy and Traveller Sites   \n",
       "All other largescale major developments    All other largescale major developments   \n",
       "Minor - Retail distribution/servicing        Minor - Retail distribution/servicing   \n",
       "Not Required - Hedgerow Removal                    Not Required - Hedgerow Removal   \n",
       "Notification - TEL type                                    Notification - TEL type   \n",
       "Prior Approval - AF2 type                                Prior Approval - AF2 type   \n",
       "Notification - AF types - Bldgs/tracks      Notification - AF types - Bldgs/tracks   \n",
       "Largescale Major Dwellings                              Largescale Major Dwellings   \n",
       "Largescale Major Retail Distri/Servicing  Largescale Major Retail Distri/Servicing   \n",
       "Not required - General                                      Not required - General   \n",
       "Smallscale Major Retail Distri/Servicing  Smallscale Major Retail Distri/Servicing   \n",
       "TCA applications                                                  TCA applications   \n",
       "Minor - Offices/R&D/Light Industry              Minor - Offices/R&D/Light Industry   \n",
       "Largescale Major Hvy Ind/Storage/Whouse    Largescale Major Hvy Ind/Storage/Whouse   \n",
       "Notification - Rail type                                  Notification - Rail type   \n",
       "Exception Notice Not Reqd (was 5day not)  Exception Notice Not Reqd (was 5day not)   \n",
       "minor - dwelling                                                  minor - dwelling   \n",
       "\n",
       "                                          freq  \n",
       "Dev_Type                                        \n",
       "Minor - Dwelling                          1048  \n",
       "Householder                                257  \n",
       "All other minor developments               154  \n",
       "CLEUD/CLOPED                               144  \n",
       "Changes of Use                             103  \n",
       "TPO applications                            78  \n",
       "Smallscale Major Dwellings                  66  \n",
       "Minor - Dwelling - PIP apps only            64  \n",
       "Listed Building Consent (alter/extend)      48  \n",
       "All other small scale major developments    21  \n",
       "Not required - S106/S52                     20  \n",
       "Advertisements                              11  \n",
       "Minor - Gypsy and Traveller Sites            9  \n",
       "All other largescale major developments      8  \n",
       "Minor - Retail distribution/servicing        5  \n",
       "Not Required - Hedgerow Removal              5  \n",
       "Notification - TEL type                      5  \n",
       "Prior Approval - AF2 type                    5  \n",
       "Notification - AF types - Bldgs/tracks       4  \n",
       "Largescale Major Dwellings                   4  \n",
       "Largescale Major Retail Distri/Servicing     2  \n",
       "Not required - General                       2  \n",
       "Smallscale Major Retail Distri/Servicing     2  \n",
       "TCA applications                             2  \n",
       "Minor - Offices/R&D/Light Industry           1  \n",
       "Largescale Major Hvy Ind/Storage/Whouse      1  \n",
       "Notification - Rail type                     1  \n",
       "Exception Notice Not Reqd (was 5day not)     1  \n",
       "minor - dwelling                             1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many records there are for each development category\n",
    "df.groupby('Dev_Type')['Dev_Type'].describe().sort_values(by='freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "556d67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOT SURE IF I WANT TO DO THIS YET - THIS CREATES A DATAFRAME FOR EVERY CATEGORY IN THE LIST\n",
    "    ALLOWS YOU TO EXPLORE THE DATA A LITTLE EASIER TO SEE WHAT TO INCLUDE/EXCLUDE'''\n",
    "df_dict ={}\n",
    "for item in all_types_list:\n",
    "    df_dict[item] = df[df['Dev_Type']==item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8fc7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dict['Householder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57feda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''First cut the source data down by exluding categories that don't share common refusal reasons - e.g.\n",
    "very specific types of development'''\n",
    "\n",
    "# maybe exclude:\n",
    "# CLUED - Certificate of Lawful Development - these generally refer to whether the use of something\n",
    "# is lawful or not, so typically refusal reasons differ here\n",
    "# TPO/TPA - Tree Protection  - generally refusals are for public amenity reasons\n",
    "#'Listed Building Consent (alter/extend)' - borderline one because it's to do with alterations/extensions\n",
    "\n",
    "exclude_cats = ['CLEUD/CLOPED','TPO applications','Not Required - Hedgerow Removal','TCA applications']\n",
    "# Prior Approval - AF2 type == agricultural stuff?\n",
    "borderline_cats = ['Listed Building Consent (alter/extend)','Prior Approval - AF2 type','Notification - Rail type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07a8eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter categories to exclude from the df. '~' negates/gives you the opposite of something\n",
    "df = df[~df['Dev_Type'].isin(exclude_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2166d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['RefusalReasons'].apply(strip_specific_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535cfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a3c463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['cleaned'].apply(strip_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46d00212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['cleaned'].apply(stopwords_and_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed5a850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of lists of the preprocessed docs, where each list is the preprocessed text\n",
    "processed_docs = df['cleaned'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ba742d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict from 'processed_docs'; each word and an integer ID. Accessed as usual dictionary[0]\n",
    "# Later passed to the model for training. Besides the id and word, it also contains frequency info\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee866e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL STEP Remove very rare and very common words: appearing < 15 times, > 30% of all documents\n",
    "# keep_n=100000 == only the 100,000 most frequent tokens in the corpus will be kept\n",
    "#dictionary.filter_extremes(no_below=15, no_above=0.2, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9718fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BOW model for each doc i.e for each we create a list of tuples (int_ref, count)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44c86fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MANUALLY CHANGE NUMBER OF TOPICS AND PASSES TO REFINE MODEL HERE. WILL BE PASSED TO MODEL IN NEXT STEP\"\"\"\n",
    "num_topics = 7\n",
    "num_passes = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcd2b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
    "#id2word is a mapping from word ids (integers) to words (strings)\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = num_topics, # select no of topics to try and create from samples\n",
    "                                   id2word = dictionary, # above comment                                 \n",
    "                                   passes = num_passes, # number of passes the model with make (> passes = more thorough????)\n",
    "                                   workers = 2) # no of extra processes to use for parallelization. Uses all available cores by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b37f47a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'considerable'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('considerable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62029e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.026*\"result\" + 0.021*\"neighbour\" + 0.019*\"fail\" + 0.017*\"form\" + 0.017*\"impact\" + 0.016*\"amenity\" + 0.016*\"design\" + 0.015*\"reason\" + 0.014*\"character\" + 0.012*\"exist\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.015*\"bullet\" + 0.014*\"guide\" + 0.013*\"design\" + 0.013*\"public\" + 0.012*\"relation\" + 0.011*\"act\" + 0.011*\"level\" + 0.010*\"overlook\" + 0.010*\"consider\" + 0.010*\"interestthe\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.036*\"countryside\" + 0.029*\"service\" + 0.029*\"facilities\" + 0.028*\"location\" + 0.025*\"unsustainable\" + 0.024*\"private\" + 0.020*\"sustainable\" + 0.017*\"open\" + 0.017*\"vehicle\" + 0.015*\"rural\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.028*\"build\" + 0.027*\"harm\" + 0.026*\"character\" + 0.024*\"conservation\" + 0.021*\"heritage\" + 0.018*\"list\" + 0.016*\"fail\" + 0.016*\"design\" + 0.015*\"consider\" + 0.015*\"appearance\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.039*\"countryside\" + 0.034*\"character\" + 0.030*\"build\" + 0.029*\"form\" + 0.022*\"rural\" + 0.021*\"landscape\" + 0.020*\"open\" + 0.017*\"location\" + 0.017*\"residential\" + 0.016*\"harm\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.033*\"access\" + 0.020*\"flood\" + 0.018*\"safe\" + 0.016*\"risk\" + 0.016*\"fail\" + 0.015*\"suitable\" + 0.014*\"conflict\" + 0.013*\"highway\" + 0.012*\"visibility\" + 0.010*\"absence\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.033*\"consider\" + 0.018*\"house\" + 0.015*\"conservation\" + 0.014*\"conflict\" + 0.014*\"provision\" + 0.014*\"affordable\" + 0.012*\"absence\" + 0.012*\"aim\" + 0.012*\"impact\" + 0.010*\"secure\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TWEAKING - For each topic, explore the words occuring in that topic and thier relative weights\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29c53b1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (1945144359.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/g4/65v8hcw105j4mynw26wj6f3r0000gp/T/ipykernel_26400/1945144359.py\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Topic: 0 \n",
    "Words: 0.026*\"result\" + 0.021*\"neighbour\" + 0.019*\"fail\" + 0.017*\"form\" + 0.017*\"impact\" + 0.016*\"amenity\" + 0.016*\"design\" + 0.015*\"reason\" + 0.014*\"character\" + 0.012*\"exist\"\n",
    "\n",
    "\n",
    "Topic: 1 \n",
    "Words: 0.015*\"bullet\" + 0.014*\"guide\" + 0.013*\"design\" + 0.013*\"public\" + 0.012*\"relation\" + 0.011*\"act\" + 0.011*\"level\" + 0.010*\"overlook\" + 0.010*\"consider\" + 0.010*\"interestthe\"\n",
    "\n",
    "\n",
    "Topic: 2 \n",
    "Words: 0.036*\"countryside\" + 0.029*\"service\" + 0.029*\"facilities\" + 0.028*\"location\" + 0.025*\"unsustainable\" + 0.024*\"private\" + 0.020*\"sustainable\" + 0.017*\"open\" + 0.017*\"vehicle\" + 0.015*\"rural\"\n",
    "\n",
    "\n",
    "Topic: 3 \n",
    "Words: 0.028*\"build\" + 0.027*\"harm\" + 0.026*\"character\" + 0.024*\"conservation\" + 0.021*\"heritage\" + 0.018*\"list\" + 0.016*\"fail\" + 0.016*\"design\" + 0.015*\"consider\" + 0.015*\"appearance\"\n",
    "\n",
    "\n",
    "Topic: 4 \n",
    "Words: 0.039*\"countryside\" + 0.034*\"character\" + 0.030*\"build\" + 0.029*\"form\" + 0.022*\"rural\" + 0.021*\"landscape\" + 0.020*\"open\" + 0.017*\"location\" + 0.017*\"residential\" + 0.016*\"harm\"\n",
    "\n",
    "\n",
    "Topic: 5 \n",
    "Words: 0.033*\"access\" + 0.020*\"flood\" + 0.018*\"safe\" + 0.016*\"risk\" + 0.016*\"fail\" + 0.015*\"suitable\" + 0.014*\"conflict\" + 0.013*\"highway\" + 0.012*\"visibility\" + 0.010*\"absence\"\n",
    "\n",
    "\n",
    "Topic: 6 \n",
    "Words: 0.033*\"consider\" + 0.018*\"house\" + 0.015*\"conservation\" + 0.014*\"conflict\" + 0.014*\"provision\" + 0.014*\"affordable\" + 0.012*\"absence\" + 0.012*\"aim\" + 0.012*\"impact\" + 0.010*\"secure\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize('character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d611a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quit code here - manual data entry required for topic naming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f17d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgjkgljfdlgjdflgjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sense of the derived topics the model suggests\n",
    "\n",
    "\n",
    "\"\"\"THIS IS A MANUAL EDIT YOU NEED TO MAKE\"\"\"\n",
    "\n",
    "\n",
    "inferred_topics = {\n",
    "    0: 'AONB',\n",
    "    1: 'Neighbours and Neighbouring Area',\n",
    "    2: 'Protected areas, conservation',\n",
    "    3: 'Conservation',\n",
    "    4: 'Affordable Housing provision',\n",
    "    5: 'Impact on neighbours/surrounds',\n",
    "    6: 'Conservation and heritage',\n",
    "    7: 'Location, open countryside',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic probabilities for each document in the corpus\n",
    "document_topics = [lda_model.get_document_topics(bow) for bow in bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6887ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to contain dictionaries with topic_num, topic probabilities for each document\n",
    "topic_probs_list = []\n",
    "\n",
    "# Iterate over the documents in the corpus\n",
    "for doc in bow_corpus:\n",
    "    # Get the topic and topic probabilities for the current document\n",
    "    topic_probs = dict(lda_model.get_document_topics(doc))\n",
    "    # Add the topic probabilities to the list\n",
    "    topic_probs_list.append(topic_probs)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of dictionaries\n",
    "topic_probs_df = pd.DataFrame(topic_probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62328fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the topic probabilities dataframe to the original df by index\n",
    "df = pd.merge(df, topic_probs_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the topic numbers in the header to your meaningful topic titles\n",
    "df = df.rename(columns=inferred_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get todays date in format (dd_mm_yy)\n",
    "today = \"(\" + date.today().strftime(\"%d_%m_%Y\") + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filename with variables used in run and the date\n",
    "filename = \"LDA_topics_\" + str(num_topics) + \"_passes_\" + str(num_passes) + today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv():\n",
    "    from pathlib import Path\n",
    "    path = \"/Users/GlassShark1/Python/Refusals Data/\"\n",
    "    filepath = Path(path + filename + \".csv\") \n",
    "    print(filepath)\n",
    "    #filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    df.to_csv(filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77aee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e69b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78fe46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unseen_document = \"The proposed development raises direct conflict with the requirements of adopted policy in the Cornwall Local Plan as the site is clearly located in the open countryside where new homes will only be permitted where there are special circumstances, none of which have been identified in this particular case. The proposed development would clearly erode the rural character of this location by introducing further built development that would result in material harm to the character and appearance of the countryside, thus not conserving the landscape character and natural beauty of the Area of Outstanding Natural Beauty (AONB) in this location. The site is not a sustainable or accessible location for a new dwelling and the development would therefore be contrary to development plan policy and cause material environmental harm to the rural character of the area, contrary to policies 1, 2, 3, 7, 12, 23 and 27 in the Cornwall Local Plan Strategic Policies 2010 - 2030 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Data preprocessing step for the unseen document\n",
    "# bow_vector = list of tuples with number representing a word in the corpus and the count of those words???\n",
    "bow_vector = dictionary.doc2bow(stopwords_and_preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    # number at the end seems to return n words and the strength of their relationship to topic????\n",
    "    print(\"Score: {}\\n Topic: {}\\n\".format(score, lda_model.print_topic(index, 10)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250dc55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging files to keep track of model / topics etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Preview BOW for our sample preprocessed document - this is on the 20th record as an example'''\n",
    "\"\"\"\n",
    "document_num = 0 #think this is just the 20th record?\n",
    "\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56caa12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ASK MN: DON'T UNDERSTAND THIS WELL - CAN'T SEE WHERE IT'S APPLIED??\n",
    "\n",
    "alpha and eta are hyperparameters that affect sparsity of the document-topic (theta) and topic-word (lambda) distributions. We will let these be the default values for now(default value is 1/num_topics)\n",
    "\n",
    "Alpha is the per document topic distribution.\n",
    "\n",
    "High alpha: Every document has a mixture of all topics(documents appear similar to each other).\n",
    "Low alpha: Every document has a mixture of very few topics\n",
    "Eta is the per topic word distribution.\n",
    "\n",
    "High eta: Each topic has a mixture of most words(topics appear similar to each other).\n",
    "Low eta: Each topic has a mixture of few words.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0253524",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Checking dictionary created'''\n",
    "\"\"\"count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 100:\n",
    "        break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488950b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
