{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b22a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de433cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet') # might not be needed once run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162d1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from an excel file. For now keep an unedited copy and one to manipulate\n",
    "og_df = pd.read_csv(\"/Users/file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71685bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = og_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6cf3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_display_max(max_rows):\n",
    "    # set display so you can see all columns, all rows and all cell contents (up to 1k characters)\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.set_option('display.max_rows', max_rows)\n",
    "    pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74c6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col_by_labels(df,column_names):\n",
    "    for col in column_names:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaaa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_df_down(df):\n",
    "    \n",
    "    #Define attribute columns with data on the permission itself\n",
    "    info_cols = ['Unnamed: 0', 'Address', 'docfragment', 'file_ext', 'filename', 'Decision', 'Link','FromSearch', 'ToSearch', 'AppTypeFrag']\n",
    "    \n",
    "    # Define columns to keep for the NLP work\n",
    "    keep_cols = ['Ref', 'Description', 'Dev_Type','DecDate', 'RefusalReasons']\n",
    "    \n",
    "    # find any other columns not in the above categories to remove - these will be those already manually categorised\n",
    "    x_train_cols = [col for col in df.columns if col not in info_cols and col not in keep_cols]\n",
    "    \n",
    "    # for unsupervised model, remove unneeded cols + manually categorised data\n",
    "    remove_cols = info_cols + x_train_cols\n",
    "    \n",
    "    # remove unwanted columns\n",
    "    df = drop_col_by_labels(df,remove_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fdd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_numbers(mess):\n",
    "    \n",
    "    # create a list of characters if the character is a letter or a space\n",
    "    strip_numbers = [char for char in mess if char.isalpha() or char == \" \"]\n",
    "    \n",
    "    # join the characters again with 'nothing' - as spaces are included above\n",
    "    strip_numbers = \"\".join(strip_numbers)\n",
    "    \n",
    "    # return the string\n",
    "    return strip_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b317c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_specific_text(mess):\n",
    "    \n",
    "    mess = mess.lower()\n",
    "    # removes common/unwanted/not valuable text and phrases from string\n",
    "    # -----------------TO DO-----------------\n",
    "    # Make this more efficient - apply to whole column rather than by message?\n",
    "    \n",
    "    # maybe replace all iterations of cornwall local plan with regex\n",
    "    text_to_remove = [\n",
    "        \"Cornwall Local Plan Strategic Policies 2010 - 2030\",\n",
    "        \"Cornwall Local Plan Strategic Policies 2010-2030\",\n",
    "        \"Cornwall Local Plan Strategic Policies\",\n",
    "        \"Cornwall Local Plan\",\n",
    "        \"National Plan Policy Framework\",\n",
    "        \"Neighbourhood Development Plan\",\n",
    "        \"National Planning Policy Framework\",\n",
    "        \"NPPF\",\n",
    "        \"Planning\",\n",
    "        \"Cornwall\",\n",
    "        \"local\",\n",
    "        \"Plan\",\n",
    "        \"Development\",\n",
    "        \"CLP\",\n",
    "        \"policies\",\n",
    "        \"contrary\",\n",
    "        \"development\",\n",
    "        \"Proposal\",\n",
    "        \"Application\",\n",
    "        \"Policy\",\n",
    "        \"Policies\",\n",
    "        \"paragraph\",\n",
    "        \"paragraphs\"\n",
    "        ]\n",
    "    \n",
    "    # for each thing you want to remove from the text\n",
    "    for phrase in text_to_remove:\n",
    "        # if the lower case version is in the lower case version of the text, replace it with nothing (delete)\n",
    "        if phrase.lower() in mess.lower():\n",
    "            #print(phrase, \" in text\")\n",
    "            mess = mess.replace(phrase.lower(), \"\")\n",
    "    \n",
    "    return mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c46510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4d096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and lemmatize\n",
    "\n",
    "def stopwords(text):\n",
    "    # creates a list of all words passed in if they are not stopwords or v.sml and returns lemmatized version\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aa7d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set JN to display full extent of data\n",
    "jupyter_display_max(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a7998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chop the df down to only the bits you will use\n",
    "df = cut_df_down(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8119f307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dev_Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minor - Dwelling</th>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Dwelling</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Householder</th>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>Householder</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All other minor developments</th>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>All other minor developments</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLEUD/CLOPED</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>CLEUD/CLOPED</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changes of Use</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>Changes of Use</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPO applications</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>TPO applications</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smallscale Major Dwellings</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>Smallscale Major Dwellings</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Dwelling - PIP apps only</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Dwelling - PIP apps only</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Listed Building Consent (alter/extend)</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>Listed Building Consent (alter/extend)</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All other small scale major developments</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>All other small scale major developments</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not required - S106/S52</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Not required - S106/S52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Advertisements</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Advertisements</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Gypsy and Traveller Sites</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Gypsy and Traveller Sites</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All other largescale major developments</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>All other largescale major developments</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Retail distribution/servicing</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Retail distribution/servicing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Required - Hedgerow Removal</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Required - Hedgerow Removal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification - TEL type</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Notification - TEL type</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior Approval - AF2 type</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Prior Approval - AF2 type</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification - AF types - Bldgs/tracks</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Notification - AF types - Bldgs/tracks</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Largescale Major Dwellings</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Largescale Major Dwellings</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Largescale Major Retail Distri/Servicing</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Largescale Major Retail Distri/Servicing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not required - General</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Not required - General</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smallscale Major Retail Distri/Servicing</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Smallscale Major Retail Distri/Servicing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCA applications</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TCA applications</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor - Offices/R&amp;D/Light Industry</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor - Offices/R&amp;D/Light Industry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Largescale Major Hvy Ind/Storage/Whouse</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Largescale Major Hvy Ind/Storage/Whouse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification - Rail type</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Notification - Rail type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exception Notice Not Reqd (was 5day not)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Exception Notice Not Reqd (was 5day not)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor - dwelling</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>minor - dwelling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count unique  \\\n",
       "Dev_Type                                                \n",
       "Minor - Dwelling                          1048      1   \n",
       "Householder                                257      1   \n",
       "All other minor developments               154      1   \n",
       "CLEUD/CLOPED                               144      1   \n",
       "Changes of Use                             103      1   \n",
       "TPO applications                            78      1   \n",
       "Smallscale Major Dwellings                  66      1   \n",
       "Minor - Dwelling - PIP apps only            64      1   \n",
       "Listed Building Consent (alter/extend)      48      1   \n",
       "All other small scale major developments    21      1   \n",
       "Not required - S106/S52                     20      1   \n",
       "Advertisements                              11      1   \n",
       "Minor - Gypsy and Traveller Sites            9      1   \n",
       "All other largescale major developments      8      1   \n",
       "Minor - Retail distribution/servicing        5      1   \n",
       "Not Required - Hedgerow Removal              5      1   \n",
       "Notification - TEL type                      5      1   \n",
       "Prior Approval - AF2 type                    5      1   \n",
       "Notification - AF types - Bldgs/tracks       4      1   \n",
       "Largescale Major Dwellings                   4      1   \n",
       "Largescale Major Retail Distri/Servicing     2      1   \n",
       "Not required - General                       2      1   \n",
       "Smallscale Major Retail Distri/Servicing     2      1   \n",
       "TCA applications                             2      1   \n",
       "Minor - Offices/R&D/Light Industry           1      1   \n",
       "Largescale Major Hvy Ind/Storage/Whouse      1      1   \n",
       "Notification - Rail type                     1      1   \n",
       "Exception Notice Not Reqd (was 5day not)     1      1   \n",
       "minor - dwelling                             1      1   \n",
       "\n",
       "                                                                               top  \\\n",
       "Dev_Type                                                                             \n",
       "Minor - Dwelling                                                  Minor - Dwelling   \n",
       "Householder                                                            Householder   \n",
       "All other minor developments                          All other minor developments   \n",
       "CLEUD/CLOPED                                                          CLEUD/CLOPED   \n",
       "Changes of Use                                                      Changes of Use   \n",
       "TPO applications                                                  TPO applications   \n",
       "Smallscale Major Dwellings                              Smallscale Major Dwellings   \n",
       "Minor - Dwelling - PIP apps only                  Minor - Dwelling - PIP apps only   \n",
       "Listed Building Consent (alter/extend)      Listed Building Consent (alter/extend)   \n",
       "All other small scale major developments  All other small scale major developments   \n",
       "Not required - S106/S52                                    Not required - S106/S52   \n",
       "Advertisements                                                      Advertisements   \n",
       "Minor - Gypsy and Traveller Sites                Minor - Gypsy and Traveller Sites   \n",
       "All other largescale major developments    All other largescale major developments   \n",
       "Minor - Retail distribution/servicing        Minor - Retail distribution/servicing   \n",
       "Not Required - Hedgerow Removal                    Not Required - Hedgerow Removal   \n",
       "Notification - TEL type                                    Notification - TEL type   \n",
       "Prior Approval - AF2 type                                Prior Approval - AF2 type   \n",
       "Notification - AF types - Bldgs/tracks      Notification - AF types - Bldgs/tracks   \n",
       "Largescale Major Dwellings                              Largescale Major Dwellings   \n",
       "Largescale Major Retail Distri/Servicing  Largescale Major Retail Distri/Servicing   \n",
       "Not required - General                                      Not required - General   \n",
       "Smallscale Major Retail Distri/Servicing  Smallscale Major Retail Distri/Servicing   \n",
       "TCA applications                                                  TCA applications   \n",
       "Minor - Offices/R&D/Light Industry              Minor - Offices/R&D/Light Industry   \n",
       "Largescale Major Hvy Ind/Storage/Whouse    Largescale Major Hvy Ind/Storage/Whouse   \n",
       "Notification - Rail type                                  Notification - Rail type   \n",
       "Exception Notice Not Reqd (was 5day not)  Exception Notice Not Reqd (was 5day not)   \n",
       "minor - dwelling                                                  minor - dwelling   \n",
       "\n",
       "                                          freq  \n",
       "Dev_Type                                        \n",
       "Minor - Dwelling                          1048  \n",
       "Householder                                257  \n",
       "All other minor developments               154  \n",
       "CLEUD/CLOPED                               144  \n",
       "Changes of Use                             103  \n",
       "TPO applications                            78  \n",
       "Smallscale Major Dwellings                  66  \n",
       "Minor - Dwelling - PIP apps only            64  \n",
       "Listed Building Consent (alter/extend)      48  \n",
       "All other small scale major developments    21  \n",
       "Not required - S106/S52                     20  \n",
       "Advertisements                              11  \n",
       "Minor - Gypsy and Traveller Sites            9  \n",
       "All other largescale major developments      8  \n",
       "Minor - Retail distribution/servicing        5  \n",
       "Not Required - Hedgerow Removal              5  \n",
       "Notification - TEL type                      5  \n",
       "Prior Approval - AF2 type                    5  \n",
       "Notification - AF types - Bldgs/tracks       4  \n",
       "Largescale Major Dwellings                   4  \n",
       "Largescale Major Retail Distri/Servicing     2  \n",
       "Not required - General                       2  \n",
       "Smallscale Major Retail Distri/Servicing     2  \n",
       "TCA applications                             2  \n",
       "Minor - Offices/R&D/Light Industry           1  \n",
       "Largescale Major Hvy Ind/Storage/Whouse      1  \n",
       "Notification - Rail type                     1  \n",
       "Exception Notice Not Reqd (was 5day not)     1  \n",
       "minor - dwelling                             1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many records there are for each development category\n",
    "df.groupby('Dev_Type')['Dev_Type'].describe().sort_values(by='freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ce1a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a set of all the different categories (all categories represented only once)\n",
    "all_types_list = set(df['Dev_Type'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f2c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the set into a list\n",
    "all_types_list = [item for item in all_types_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4515f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOT SURE IF I WANT TO DO THIS YET - THIS CREATES A DATAFRAME FOR EVERY CATEGORY IN THE LIST\n",
    "    ALLOWS YOU TO EXPLORE THE DATA A LITTLE EASIER TO SEE WHAT TO INCLUDE/EXCLUDE'''\n",
    "df_dict ={}\n",
    "for item in all_types_list:\n",
    "    df_dict[item] = df[df['Dev_Type']==item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['RefusalReasons'].apply(strip_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['cleaned'].apply(strip_specific_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d00212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['cleaned'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90687df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6489de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(WordNetLemmatizer().lemmatize('went', pos = 'v')) # past tense to present tense\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'''\n",
    "Preview a document after preprocessing\n",
    "'''\n",
    "document_num = 50\n",
    "doc_sample = 'This disk has failed many times. I would like to get it replaced.'\n",
    "\n",
    "print(\"Original document: \")\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(preprocess(doc_sample))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for cell in df['cleaned']:\n",
    "    processed_docs.append(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba742d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create dict from 'processed_docs' containing the number of times a word appears \n",
    "in the training set using gensim.corpora.Dictionary\n",
    "'''\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0253524",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Checking dictionary created'''\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef05e34",
   "metadata": {},
   "source": [
    "** Gensim doc2bow **\n",
    "\n",
    "doc2bow(document)\n",
    "\n",
    "Convert document (a list of words) into the bag-of-words format = list of (token_id, token_count) 2-tuples. Each word is assumed to be a tokenized and normalized string (either unicode or utf8-encoded). No further preprocessing is done on the words in document; apply tokenization, stemming etc. before calling this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee866e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "OPTIONAL STEP\n",
    "Remove very rare and very common words:\n",
    "- words appearing less than 15 times\n",
    "- words appearing in more than 30% of all documents\n",
    "'''\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.3, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9718fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to 'bow_corpus'\n",
    "'''\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Preview BOW for our sample preprocessed document'''\n",
    "\n",
    "document_num = 20\n",
    "\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2837cc3",
   "metadata": {},
   "source": [
    "Step 4: Running LDA using Bag of Words\n",
    "We are going for 10 topics in the document corpus.\n",
    "\n",
    "** We will be running LDA using all CPU cores to parallelize and speed up model training.**\n",
    "\n",
    "Some of the parameters we will be tweaking are:\n",
    "\n",
    "num_topics is the number of requested latent topics to be extracted from the training corpus.\n",
    "\n",
    "id2word is a mapping from word ids (integers) to words (strings). It is used to determine the vocabulary size, as well as for debugging and topic printing.\n",
    "\n",
    "workers is the number of extra processes to use for parallelization. Uses all available cores by default.\n",
    "\n",
    "alpha and eta are hyperparameters that affect sparsity of the document-topic (theta) and topic-word (lambda) distributions. We will let these be the default values for now(default value is 1/num_topics)\n",
    "\n",
    "Alpha is the per document topic distribution.\n",
    "\n",
    "High alpha: Every document has a mixture of all topics(documents appear similar to each other).\n",
    "Low alpha: Every document has a mixture of very few topics\n",
    "Eta is the per topic word distribution.\n",
    "\n",
    "High eta: Each topic has a mixture of most words(topics appear similar to each other).\n",
    "Low eta: Each topic has a mixture of few words.\n",
    "** passes ** is the number of training passes through the corpus. For example, if the training corpus has 50,000 documents, chunksize is 10,000, passes is 2, then online training is done in 10 updates:\n",
    "\n",
    "#1 documents 0-9,999\n",
    "#2 documents 10,000-19,999\n",
    "#3 documents 20,000-29,999\n",
    "#4 documents 30,000-39,999\n",
    "#5 documents 40,000-49,999\n",
    "#6 documents 0-9,999\n",
    "#7 documents 10,000-19,999\n",
    "#8 documents 20,000-29,999\n",
    "#9 documents 30,000-39,999\n",
    "#10 documents 40,000-49,999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'''\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 8, # select no of topics to try and create from samples\n",
    "                                   id2word = dictionary, # use the counts of words to do this?? Check correct??                                 \n",
    "                                   passes = 50, # number of passes the model with make (> passes = more thorough????)\n",
    "                                   workers = 2) # use both processing cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62029e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For each topic, explore the words occuring in that topic and its relative weight'''\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82dfba",
   "metadata": {},
   "source": [
    "Step 6: Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOT SURE WHAT THE BELOW CODE ACTUALLY DOES'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7827b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "unseen_document = newsgroups_test.data[num]\n",
    "print(unseen_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing step for the unseen document\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bee289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newsgroups_test.target[num])\n",
    "\n",
    "#The model correctly classifies the unseen document with 'x'% probability to the X category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a951a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
